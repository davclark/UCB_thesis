\graphicspath{{evil-ndi/}}

\chapter{Learning \texorpdfstring{``Evil''}{"Evil"} Non-Representative Climate Numbers}
\label{chap:evilndi}

As described above, there is some debate surrounding the value of scientific or
numeric information regarding climate change. Indeed, some have claimed that
such interventions will only serve to polarize individuals, thus making the
situation worse than it already is. However, some organizations publish
out-of-context facts to try to undercut the reality or gravity of human-caused
climate change. Such numbers are often blatantly cherry picked. For example, the
Earth’s temperature decreased (by 0.2oF) from 1940 to 1975 (Jastrow, Nierenberg,
\& Seitz, 1991). This surprising fact, though, hardly contradicts the ever more
obvious warming trend over the last 125+ years, as one can pluck many ``trends''
in noisy time series by picking endpoints that are oddly high or low. Given this
rather clear intent to mislead (Oreskes \& Conway, 2010), we (partly
tongue-in-cheek) label these numbers ``evil.'' 

Our three hypotheses were that misleading facts would reduce:
\begin{enumerate}
    \item Participants’ climate change acceptance, 
    \item ratings of their knowledge of the issue, and 
    \item their climate-change funding preferences.
\end{enumerate}
Of course, lest we erode participants’ acceptance of anthropogenic climate
change more than fleetingly, we debriefed them right afterward with more
complete information---including the mechanism and a large dose of relevant
facts. It should be clear that we're not interested in perfecting this approach! 

Here we go into the much more easily obtained effects we demonstrated using the
anti-climate NDI. This is much shorter, as we were mostly curious to see if we
could get an effect. In particular, we only did one experiment with one
undergraduate seminar course (where we could be sure to administer a proper
debriefing).

\section{Study: UC classroom intervention with \texorpdfstring{“evil”}{"evil"}
    numbers}

\subsection{Methods} 
\label{sec:evilndi-methods}

\subsubsection{Materials and Procedure}

Participants were engaged in one of two similar misleading numeracy
interventions. In both versions, survey methods were as described in
Chapter~\ref{chap:survey}. This study utilized a somewhat compact version of a
pre- and post-intervention test using only the 14 items in
Table~\ref{table:rtmd-questions} (up through \textsf{engage}), plus a
self-rating of climate-change knowledge.  

In the “no pre-test blast” version of the intervention, participants estimated
each of eight items prior to receiving the feedback values, with an emphasis on
maximizing the quantity of feedback numbers presented to the participant. To
this end, this eight-item survey included only a post-test (i.e., no pre-test),
and lacked a policy component (thus, it was an EI intervention, lacking ``P'' or
``C'', simlar to the approach used in Chapter~\ref{chap:two}). 

A more comprehensive engagement containing only two items was administered to
the rest of the class. This version included a pre-test and additional questions
about each item. In addition, we asked students about their surprise level after
each feedback value and requested both their climate-change funding Policies and
post-feedback policy Changes versus various UNDP millennium goals.  Thus, this
latter variant was a full EPIC intervention.

Note that while this experiment is presented first as a motivation for the
following chapters, it was actually carried out \emph{after} a number of
experiments in Chapters~\ref{chap:prondi} and \ref{chap:mechanism}. Thus, a
number of experimental design choices made here are motivated by findings from
experiments in those chapters.

\subsubsection{Participants}

Two classes of UC Berkeley undergraduates were engaged in this intervention
($N=104$). 59 students completed the 8-item “no pre-test” version of the
experiment and 45 completed the 2-item full EPIC intervention. All participants
were retained after examining the coherence of survey responses.

% TODO: demographics

\subsection{Results}

Split into separate sections! 
% TODO: Also note changes for each item / individual comparisons here.

As hypothesized, policy preferences for funding UN goals
related to climate change dropped ($\chi^2(1)=22$, $p<0.01$) for all eight funding
priorities. (Unfortunately for global warming as a social priority, the highest
mean pre-test preference for funding climate change initiatives reached only a
50-50 split of available funds.) Also, as hypothesized, mean climate change
acceptance dropped significantly, from 6.5 on the pre-test to 6.2 on the
post-test for the two-item group (6\% of available room, for a 9-point scale,
t(42)=-4.3, p<0.001), and significantly to 5.9 for the eight-item group (12\% of
available room, t(88.6)=‑2.61, p<0.005). Note that these shifts were also in the
direction of ambivalence (a ``5'' rating), and may reflect confusion rather than
disagreement. Our third hypothesis was also supported, as self-rated knowledge
dropped from a mean of 5.0 on the pre-test to 4.5 for the two-item group (12\% of
available room, t(44)=-2.5, p<0.01), and plummeted to 2.9 on eight-item survey
(t(87.2)=- 5.3, p<0.001). This latter decrease, 2.1, represents 53\% of the
available room to drop on a 9-point scale, which is exceptionally large.  It is
clear that even relatively educated members of the public (e.g., undergraduates
at a top-tier university) are highly susceptible to misleading, cherry picked
facts. Such facts are clearly known to organizations attempting to undermine the
overwhelming scientific consensus about climate change. Thus, cognitive science
must counter the increasing sophistication with which such organizations
distribute misleading information.

\subsection{Discussion}

In stark contrast to arguments that numeracy is polarizing \parencite{kahan}, we
have provided an existence proof that appropriately selected scientific facts
can have a profound effect across a population. In particular, we have
demonstrated marked erosion of self-confidence in one's own knowledge, as well
as belief and concern regarding anthropogenic climate change---even in our
relatively liberal and anthropogenic-climate-change-acceting sample of UC
Berkeley undergraduates.  Such results were observed with as little as
\emph{two} numbers.
% Still need to grab stuff from above
Consider the effect of the writings of \textcite{mueller}, a prominent professor
at our ostensibly liberal institution. We must assume that educated, liberal
individuals may be easily swayed by a small dose of factual (but
non-representative) numerical or scientific information from such a source.

A central point illustrated by this study is that individual's understandings
are demonstrably fragile. Even an intervention of a few minutes can massively
undercut individual's confidence in thier own knowledge, along with overall
belief and concern about global climate change.

% TODO: There are two points here, one about the difference between self-guided
% and directed education, and one about the ability of scientific information to
% work for both sides of the climate “debate”
A secondary point to consider is that, As noted by \textcite{kahan,mccright},
individuals tend to be little-affected by self-guided educational efforts. Thus,
one might conclude that climate change accepters are unlikely to come into
contact with such numbers on their own.  However, there are concerted efforts to
distribute such numbers on the internet and elsewhere. As shown above and as
noted by \cite{mccright}, scientific information might push individuals both
towards scientific consensus, as well as \emph{away} from it.  Thus, it seems
wise to build a solid foundation of climate change-relevant knowledge in the
American populace. 

\section*{Acknowledgements}

The work reported in this chapter has been previously published, in part, in
\textcite{clark_knowledge_inpress}.  All such material is re-used here with the
permission of my co-authors, the publishers, and the Graduate Division at the
University of California, Berkeley.
