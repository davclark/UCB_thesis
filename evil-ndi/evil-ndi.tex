\graphicspath{{evil-ndi/}}

\chapter{Learning ``Evil'' Non-Representative Climate Numbers}
\label{chap:evilndi}

Here we go into the much more easily obtained effects we demonstrated using the
anti-climate NDI. This is much shorter, as we were mostly curious to see if we
could get an effect. We're not interested in perfecting this approach! In
particular, we only did one experiment with one undergraduate seminar course
(where we could be sure to administer a proper debriefing).

\section{Actual Abstract (remove heading before submission)}

Some organizations publish out-of-context facts to try to undercut the reality
or gravity of human-caused climate change. Such numbers are often blatantly
cherry picked. For example, the Earth’s temperature decreased (by 0.2oF) from
1940 to 1975 (Jastrow, Nierenberg, \& Seitz, 1991). This surprising fact, though,
hardly contradicts the ever more obvious warming trend over the last 125+ years,
as one can pluck many ``trends'' in noisy time series by picking endpoints that
are oddly high or low. Given this rather clear intent to mislead (Oreskes \&
Conway, 2010), we (partly tongue-in-cheek) label these numbers ``evil.'' Our three
hypotheses were that misleading facts would reduce participants’ climate change
acceptance, ratings of their knowledge of the issue, and their climate-change
funding preferences. Of course, lest we erode participants’ acceptance of
anthropogenic climate change more than fleetingly, we debriefed them right
afterward with more complete information––including the mechanism and a large
dose of relevant facts.

\section{Methods} The survey and instructional materials were analogous to those used for
the paper-and-pencil mechanism study described in Ranney et al. (2012a). The
primary difference was that the mechanism was replaced with one of two
interventions. In one version, part of a class of UCB undergraduates (n=59)
estimated each of eight items prior to receiving the feedback values, with an
emphasis on maximizing the quantity of feedback numbers presented to the
participant. To this end, this eight-item survey included only a post-test
(i.e., no pre-test), and lacked a policy component (thus, it was an EI
intervention, lacking ``P'' or ``C''). A more comprehensive engagement containing
only two items was administered to the rest of the class (n=45), and this
version included a pre-test and additional questions about each item. We asked
students about their surprise level after each feedback value and requested both
their climate-change funding Policies and post-feedback policy Changes versus
various UNDP millennium goals.

\section{Results and Discussion}

Split into separate sections! 
% TODO: Also note changes for each item / individual comparisons here.

As hypothesized, policy preferences for funding UN goals
related to climate change dropped ($\chi^2(1)=22$, $p<0.01$) for all eight funding
priorities. (Unfortunately for global warming as a social priority, the highest
mean pre-test preference for funding climate change initiatives reached only a
50-50 split of available funds.) Also, as hypothesized, mean climate change
acceptance dropped significantly, from 6.5 on the pre-test to 6.2 on the
post-test for the two-item group (6\% of available room, for a 9-point scale,
t(42)=-4.3, p<0.001), and significantly to 5.9 for the eight-item group (12\% of
available room, t(88.6)=‑2.61, p<0.005). Note that these shifts were also in the
direction of ambivalence (a ``5'' rating), and may reflect confusion rather than
disagreement. Our third hypothesis was also supported, as self-rated knowledge
dropped from a mean of 5.0 on the pre-test to 4.5 for the two-item group (12\% of
available room, t(44)=-2.5, p<0.01), and plummeted to 2.9 on eight-item survey
(t(87.2)=- 5.3, p<0.001). This latter decrease, 2.1, represents 53\% of the
available room to drop on a 9-point scale, which is exceptionally large.  It is
clear that even relatively educated members of the public (e.g., undergraduates
at a top-tier university) are highly susceptible to misleading, cherry picked
facts. Such facts are clearly known to organizations attempting to undermine the
overwhelming scientific consensus about climate change. Thus, cognitive science
must counter the increasing sophistication with which such organizations
distribute misleading information.

