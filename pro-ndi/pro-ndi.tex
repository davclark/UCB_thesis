\graphicspath{{pro-ndi/}}

\chapter{Learning Representative Climate-Relevant Numbers}
\label{chap:prondi}

Notes - contrast with mechanism study. Much less scaffolding, more burden on the
student to make sense, more burden on instructional design to make things clear.

\section{Actual Abstract (delete heading before submission)}

\section{Altering Beliefs with Factual Numbers}

This came from the CogSci 2013 paper - edit or cut

The Numerically-Driven Inferencing (NDI) paradigm has yielded marked
attitudinal and conceptual shifts with quite minimalist interventions. NDI and
one of its procedures, EPIC (both introduced by Ranney and colleagues in 2001),
represent a particularly compact, well-specified intervention. In EPIC,
participants (1) provide an Estimate for each policy-relevant item’s quantity;
(2) state a preferred target (or monetary allocation) Policy (or Preference) for
each quantity; (3) receive actual quantities as feedback to Incorporate (as new
``Information''); and (4) indicate whether one’s policy has Changed upon receiving
feedback. With even a single well-selected quantity, the EPIC procedure’s
feedback often shifts participants’ attitudes. Conceptual changes resulting from
EPIC are often remarkably durable for such a minimal intervention (e.g., Ranney
et al., 2008), as evidenced by increased estimation accuracy up to 12 weeks
after the procedure (Munnich, Ranney, \& Bachman, 2005). Therefore, we sought to
employ NDI interventions in addition to the mechanism intervention from Study 1
and before. Specifically, we presented different participant groups with
numerical information that is relevant to global climate change acceptance. We
used numbers that were likely to boost acceptance (Study 3), as well as numbers
that we thought might erode individual's belief in climate change (Study 2).

\section{Online experiment with UC Undergrads}

Given the efficacy of “evil” numbers and previous successes of the NDI paradigm,
this study assessed the efficacy of numbers that support the claim of global
climate change. Again partly tongue-in-cheek, we call these “saintly” numbers.
Given prior NDI studies of similarly “shocking” magnitudes (e.g., Garcia de
Osuna, et al., 2004), our hypothesis was that the accurate feedback would
increase participants’ climate change acceptance, but diminish self-confidence
in their knowledge of the issue.


\subsection{Methods}

This study used an on-line version of materials, as did Study 1, and used a
UCB-RPP pre-test survey (completed by 30 participants) that yielded, on average,
an 18-day delay between pre-test and intervention. We queried individuals (N=60)
about eight quantities. The eight items included questions directed at
participants’ surprise and their reactions to each number (fictitious monetary
policies were left out of this version due to attitude shifts observed in the
simplified 8-item “evil” intervention). An added feature of the online
intervention is that we could remind individuals of the estimates they gave on
the same page on which they incorporated numerical feedback, ensuring that they
contrasted the two. As with Study 1’s online survey, an attitude and belief
post-test was administered immediately after our intervention and also after a
retention interval.


\subsection{Results and Discussion}

Attitudes, acceptance, and beliefs regarding climate change remained stable
after this intervention with “saintly” numbers (6.71 pre and 6.67 post). This
stability was unexpected (but see below for explanations), especially because
these items (as with the “evil items) were, as anticipated, able to
significantly erode self-rated knowledge (5.3 to 4.0, t(29)=-3.6, p<0.01). This
erosion was comparable to that found with the “evil” numbers. These items also
ranked relatively high on participant surprise compared to the 400-words from
Study 1. Mean surprise ratings across items was 4.8, while surprise ratings for
the 400 words was 2.9 (all ratings above “1” indicate some level of surprise).

One of the most surprising numbers (at 5.2) was the percentage of active
researchers who support the tenets of anthropogenic climate change, reflective
of the strong relationship between perceived scientific consensus and acceptance
of climate change reported in Lewandowsky, Gignac, and Vaughan (2013). The two
numbers most comparable to the statistics in the 400 words were similarly
surprising, with the rises in atmospheric methane and atmospheric CO2 ranking at
5.9 and 5.1, respectively.

\emph{We can make a parallel here to Kahneman's pain studies / retrospective vs
experiencing.}

\subsubsection{Results on attitutudes}

In spite of these powerful impacts, Study 3 yielded no effect on beliefs and
attitudes. This lack of effect is counter to prior NDI studies, in which
individuals’ preferences and beliefs were often markedly shifted by even a
single number. An experimental silver lining here is the demonstration that
participants will not report greater climate change acceptance merely by dint of
experimenter demand! One possible explanation is due to a methodological change:
In prior NDI and RTMD studies, participants were explicitly told (a) that all
feedback statistics and other information were fully accurate (and that the
study involved no deceptions), and (b) the particular scientific/literature
source both for each statistic that was sought and each provided as feedback.
It is thus possible that participants were less compelled by the authority of
this study’s statistics, compared to those in Study 2.  Another possibility is
that, as in Study 2, participants were left feeling less knowledgeable—weakening
any boost these surprising numbers could have on climate change acceptance.
Individuals perhaps lacked an appropriate context for integrating this
information. The next study illustrates one way to contextualize such numbers.

