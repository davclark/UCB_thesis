\graphicspath{{pro-ndi/}}

\chapter{Learning Representative Climate-Relevant Numbers}
\label{chap:prondi}

Notes - contrast with mechanism study. Much less scaffolding, more burden on the
student to make sense, more burden on instructional design to make things clear.

\section{Actual Abstract (delete heading before submission)}

\section{Altering Beliefs with Factual Numbers}

This came from the CogSci 2013 paper - edit or cut

The Numerically-Driven Inferencing (NDI) paradigm has yielded marked
attitudinal and conceptual shifts with quite minimalist interventions. NDI and
one of its procedures, EPIC (both introduced by Ranney and colleagues in 2001),
represent a particularly compact, well-specified intervention. In EPIC,
participants (1) provide an Estimate for each policy-relevant item’s quantity;
(2) state a preferred target (or monetary allocation) Policy (or Preference) for
each quantity; (3) receive actual quantities as feedback to Incorporate (as new
``Information''); and (4) indicate whether one’s policy has Changed upon receiving
feedback. With even a single well-selected quantity, the EPIC procedure’s
feedback often shifts participants’ attitudes. Conceptual changes resulting from
EPIC are often remarkably durable for such a minimal intervention (e.g., Ranney
et al., 2008), as evidenced by increased estimation accuracy up to 12 weeks
after the procedure (Munnich, Ranney, \& Bachman, 2005). Therefore, we sought to
employ NDI interventions in addition to the mechanism intervention from Study 1
and before. Specifically, we presented different participant groups with
numerical information that is relevant to global climate change acceptance. We
used numbers that were likely to boost acceptance (Study 3), as well as numbers
that we thought might erode individual's belief in climate change (Study 2).

As before, survey methods employed in the following studies are described in
detail in Section~\ref{chap:survey}.

\section{Study 1: Online experiment with UC Undergrads}

Given the efficacy of “evil” numbers and previous successes of the NDI paradigm,
this study assessed the efficacy of numbers that support the claim of global
climate change. Again partly tongue-in-cheek, we call these “saintly” numbers.
Given prior NDI studies of similarly “shocking” magnitudes (e.g., Garcia de
Osuna, et al., 2004), our hypothesis was that the accurate feedback would
increase participants’ climate change acceptance, but diminish self-confidence
in their knowledge of the issue.


\subsection{Methods}

\subsubsection{Materials and Procedure}

This study used an on-line version of materials, as did Study 1, and used a
pre-test survey that was completed, on average, 18-days prior to the
intervention. In the main intervention, we queried individuals about eight
quantities (listed in Appendix~\ref{app:numbers}). The eight items were
accompanied by questions directed at participants’ surprise and their reactions
to each number. Fictitious monetary policies were left out of this version, as
simple attitude shifts were readily observed in the simplified 8-item “evil”
intervention, and these shifts are more directly comparable across experiments.
An added feature of the online intervention is that we could remind individuals
of the estimates they gave on the same page on which they incorporated numerical
feedback, ensuring that they contrasted the two. As with online surveys in
Chapter~\ref{chap:mechanism}, an attitude and belief post-test was administered
immediately after our intervention and also after a retention interval.
% TODO: What was retention interval?

\subsubsection{Participants}

UC Berkeley undergrads ($N=60$) were recruited via the Research Participation
Pool (RPP). The RPP pre-test was completed by 30 of these participants. 
% TODO: Demographics

% \subsubsection{Analysis}
% 
% Analyses here were largely analagous to those described in
% Section~\ref{sec:mech-online-methods}.

\subsection{Results}

Because these items were, as anticipated and as with the “evil” items, able to
significantly erode self-rated knowledge (5.3 to 4.0, $t(29)=-3.6$, $p<0.01$).
This erosion was comparable to that found with the “evil” numbers.  These items
ranked relatively high on participant surprise compared to the (significantly
effective) 400-word mechanism intervention from Chapter~\ref{chap:mechanism}.
The mean surprise rating across items was 4.8.  While this is a bit lower than
surprise ratings for “evil” numbers in Chapter~\ref{chap:evilndi}, it markedly
exceeds the mean surprise rating for the 400 words was 2.9 (all ratings above
“1” indicate some level of surprise). Thus, the immediate affective impact of
these numbers was reported as \emph{higher} than an intervention that (as we'll
see in Chapter~\ref{chap:mechanism}) effectively supported significant shifts in
student attitudes along with other measures.

One of the most surprising numbers (at 5.2) was the percentage of active
researchers who support the tenets of anthropogenic climate change, reflective
of the strong relationship between perceived scientific consensus and acceptance
of climate change reported in Lewandowsky, Gignac, and Vaughan (2013). The two
numbers most comparable to the statistics in the 400 words were similarly
surprising, with the rises in atmospheric methane and atmospheric CO2 ranking at
5.9 and 5.1, respectively.


\subsubsection{GW attitutudes}

In spite of these powerful impacts attitudes, acceptance, and beliefs regarding
climate change remained stable after this intervention with “saintly” numbers
(6.71 pre and 6.67 post).  This lack of effect is counter to prior NDI studies
(as well as the results reported in Chapter~\ref{chap:mechanism}), in which
individuals’ preferences and beliefs were often markedly shifted by even a
single number. 

\subsection{Discussion}

Regarding surprise in comparison to mechanism, we can make a parallel here to
Kahneman's pain studies / retrospective vs experiencing.

Note that not all items had sources. Many were likely difficult to understand
(wordings in Appendix~\ref{app:numbers} are reflective of the final wordings
used in Study 2). Unlike Study 2, this intervention \emph{did} include the
assertion that the study involved no deceptions.

An experimental silver lining here is the demonstration that
participants will not report greater climate change acceptance merely by dint of
experimenter demand! One possible explanation is due to a methodological change:
In prior NDI and RTMD studies, participants were explicitly told that all
feedback statistics and other information were fully accurate (and that the
study involved no deceptions). This was \emph{also} the case in the experiment,
so such assertions are clearly not sufficient to drive changes in attitude and
belief.  One difference that \emph{may} partially account for our lack-of-effect
is that many previous studies also provided the particular scientific/literature
source both for each statistic that was sought and each provided as feedback.

So, it is possible that participants were less compelled by the authority of
this study’s statistics, compared to those in Chapter~\ref{chap:evilndi}.
Another possibility is that, as in Chapter~\ref{chap:evilndi}, participants were
left feeling less knowledgeable—weakening any boost these surprising numbers
could have on climate change acceptance.  

A final possiblity is that the effect of this numerical intervention would be
strengthened by an appropriate context for integrating this information. That
is, perhaps we could not simply present our numerical information as it was in
isolation with the expectation of an effect. Indeed, as we report in
\cite{clark_knowledge_inpress}, similar numbers had little immediate effect on
high-school students as a part of a global warming mechanism curriculum.
However, students exposed to numbers like those in this Study retained the
effects of the curriculum to a greater extent than students in a control group.

\section{Study 2: Online intervention on Mechanical Turk}

\subsection{Methods}

\subsubsection{Materials and Procedure}

After the difficulty obtaining shifts in GW attitudes and beliefs above, I was
able to replicate this difficulty by presenting the same materials to a more
general population on Amazon Mechanical Turk (though I won't go through the
process of reporting another null result here). I then engaged in a thorough
examination of the wording of the items (also discovering that one item was off
by an order of magnitude). This process was relatively informal, and consisted
of showing the items to naïve individuals and asking them if they had any
difficulty understanding them. Descriptions were iterated until they appeared to
make sense to non-experts.

Note that in the process of streamlining instructions, I removed instructions to
the effect that NO deceptions were used. This is in contrast to the previous
(ineffective) study that did include such an instruction.  In addition, in this
study even more than in the above study, the inclusion of information about
authority was scant (e.g., the more accessible phrase “journal article” replaced
phrases such as “article published in PNAS”).

\subsubsection{Data quality on Amazon Mechanical Turk}
\label{sec:mturk-problems}

The use of an anonymous, on-line labor pool raises concerns about data quality.
For example, people may try to take the survey again or they may lie about their
demographics (i.e., claiming they are U.S. residents so that they may gain the
credit). Re-taking is one of the most easily guarded against concerns on Amazon
Mechanical Turk, as Amazon will attempt to enforce this if requested, as was
done in this study. However, in addition, no IP addresses were repeated in the
participant group for this study.

Amazon will attempt to restrict individuals to the U.S. if requested, and this
was done for this experiment. An additional layer of verification of location is
straightforward using “geo IP” databases. In this case, geographical locations
were retrieved from the freely available \textcite{maxmind-database}. On our
survey, participants indicated the state they reside in. Participant IP
addresses were subsequently checked against this reported location. Here, two
individuals IP’s appeared to be located in Germany and Guatemala, and thus these
participants were excluded. Most other participants had IP addresses that
resolved to the state they claimed to be from. One participant’s IP address was
not listed in the MaxMind database, and was traced to either Hughes Net or
Bright Home, both U.S.-only satellite internet providers.

\subsection{Results}

Numbers were again ranked as surprising.

\subsubsection{GW acceptance supported by clear numerical information}

\begin{figure}
    \centering
    \includegraphics{CCO-prondi-gw.pdf}
    \caption{Shifts in GW ratings in Mechanical Turk intervention with
        climate-change-supporting numbers.}
    \label{fig:prondi-gw}
\end{figure}

\subsubsection{Self-confidence in GW knowledge is still eroded}

\begin{figure}
    \centering
    \includegraphics{CCO-prondi-knw.pdf}
    \caption{Erosion of confidence in self-ratings of GW knowledge in Mechanical
        Turk intervention with climate-change-supporting numbers.}
    \label{fig:prondi-knw}
\end{figure}

\subsubsection{No observed effect of political variables}

% TODO
With this sample, we are able to examine the effects of
conservativism or political party. Figure XXX shows attitudes broken out by
Republican, Democrat (and Other).

\subsection{Discussion}

As compared with Study 1, the primary change was an increase in the fluency of
materials. While we should be careful in making comparisons across populations,
the similarity in the effects reported in Chapter~\ref{chap:mechanism} provide
some evidence that similar interventions perform similarly across UC Berkeley
undergrads and Mechanical Turkers. Thus, it seems reasonable to recommend that
careful attention be given to materials like those used in this chapter. Items
should be tested for comprehensibility with naïve individuals prior to
attempting to use them in a belief or behavioral change intervention.

Note also that for reasons of time and simplicity, we did not include policy
shifts in this study. However, we can still compare the size of belief and
attitude shifts with the 2-item study described in Chapter~\ref{chap:evilndi}
and infer that we are seeing attitudinal shifts of a similar magnitude.

\section{Summary and Conclusions}

Despite the “failure” of Study 1 above, it affords us a number of insights.
Critically, we cannot simply throw a set of numbers at Americans and expect that
to impact their beliefs and attitudes. A real silver lining here is
support for the fact that shifts, when we do observe them, are \emph{not} driven
merely by experimenter demand.

Combined with Chapter~\ref{chap:evilndi}, we have now witnessed numeracy-based
interventions that push individuals towards and away from the scientific
consensus on anthropogenic climate change. In addition, we have seen that even
when students claim surprise regarding a set of numbers, they may not be
influenced by these numbers unless they are presented with the necessary clarity.

It should be noted also that as in Chapter~\ref{chap:evilndi}, participants were
left feeling less knowledgeable than they reported prior to the intervention. It
remains for future research to determine what impact this might have on
behavior, but it seems likely that a lack of confidence would likley
inhibit public statements or commitments regarding climate change.

Our group has also integrated such numbers with  more comprehensive
interventions. For example, \textcite{clark_knowledge_inpress} reports on the
utility of such numbers in improving retention of a climate change curriculum
described in \textcite{felipe_numerical_2012}. In the following chapter, we'll
see another relatively simple, but more comprehensive intervention that includes two
of our more surprising numbers. This intervention leaves participants both more informed
\emph{and} more confident in their own knowledge.

\section*{Acknowledgements}

The work reported in this chapter has been previously published, in part, in
\textcite{clark_knowledge_inpress}.  All such material is re-used here with the
permission of my co-authors, the publishers, and the Graduate Division at the
University of California, Berkeley.
